# Звіт з аналізу продуктивності та навантаження системи

## 1. Сценарій тестування навантаження

Відповідно до завдання, було підготовлено тест, що імітує найбільш типову роботу сервісу — перегляд списку користувачів та постів.

- **Інструмент:** Artillery.
- **Сценарій:** Поступове зростання навантаження протягом 60 секунд від 5 до 20 запитів на секунду.
- **Ендпоінти:** `GET /users`, `GET /posts`.

## 2. Результати профілювання

Для збору даних про стан системи було використано інструменти **Clinic.js Doctor** та **Flame**.

- **Використання RAM:**
  Загальний обсяг фізичної пам'яті, виділеної процесу (RSS), залишався стабільним на рівні близько 115 MB. Відсутність постійного зростання графіку пам'яті (Heap) після завершення тесту підтверджує відсутність витоків пам'яті.

- **Навантаження на CPU:**
  Зафіксовано значні сплески активності процесора (до 350%). Clinic.js Doctor видав попередження про I/O Issue.

- **Аналіз через Clinic.js Flame:**
  Найбільше часу витрачається на виконання функції `findAll()` (вибірка всіх записів без обмежень) та наступну серіалізацію JSON. Оскільки `findAll()` зчитує всю таблицю одночасно, це стає головним джерелом навантаження на систему.

## 3. Аналіз роботи з базою даних та мережею

Оскільки база даних розгорнута на віддаленому сервісі, аналіз логів `responseTime` виявив наступні затримки:

- Середній час відповіді для `/users`: 579.91 мс
- Середній час відповіді для `/posts`: 359.20 мс

Ці дані підтверджують, що використання функції `findAll()` без фільтрації чи лімітів призводить до over-fetching — надлишкової вибірки даних, що в свою чергу перевантажує мережевий канал.

## 4. Висновки

За результатами аналізу, для покращення роботи сервісу необхідно впровадити такі зміни:

1. **Замінити повну вибірку `findAll()` на пагіновану**: використовувати параметри **`limit`** та **`offset`** у запитах до бази даних. Це усуне попередження про I/O Issue та радикально зменшить навантаження на CPU.
2. **Оптимізація запитів:** зменшення об'єму даних у кожній відповіді дозволить Event Loop швидше обробляти паралельні запити користувачів, підвищуючи загальну пропускну здатність системи.
